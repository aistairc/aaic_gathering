{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChainerMNのプログラムについて、[MNIST](https://en.wikipedia.org/wiki/MNIST_database)(手書き数字認識)のサンプルを用いて説明します。<br>\n",
    "ここでは、以下のモジュールがロードされていることを前提とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "import chainermn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、ネットワークのモデルを定義します。<br>\n",
    "ここでは、各層が1000個のユニットで出力が10個のである単純な3層のネットワーク(MLP: Multi Layer Perceptron)を用います。<br>\n",
    "\\__init\\__でネットワークの接続を定義し、\\__call\\__でデータの流れを定義しています。<br>\n",
    "ネットワークのモデルの定義に関してはChainerと同様で、詳細は以下のサイトを参照してください。<br>\n",
    "http://docs.chainer.org/en/latest/tutorial/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(784, n_units),  \n",
    "            l2=L.Linear(n_units, n_units),\n",
    "            l3=L.Linear(n_units, n_out),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "    \n",
    "model = L.Classifier(MLP(1000, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChainerMNはデータ並列型の分散処理を採用しています。各ワーカプロセスがモデルを保持し、バッチ（データセット）に対して勾配を計算し、計算結果を用いてワーカプロセス間で学習モデルの更新を行うことで分散深層学習を行います。具体的には、Chainerで行っていたForward, Backward, Optimizeの処理を分散化し、BackwardとOptimizeの間にAllReduce(各ワーカプロセスの結果を集約して集約した結果を各ワーカプロセスへ送付する)を行うことで実現しています。この分散化にはMPI(Message Passing Interface)と呼ばれる高性能計算(HPC)で一般的に使われている実装が用いられています。詳細については以下のサイトを参照してください。<br>\n",
    "http://chainermn.readthedocs.io/en/latest/tutorial/overview.html\n",
    "\n",
    "\n",
    "ChainerMNで分散深層学習を行うためには、まず、Communicatorを作成します。<br>\n",
    "Communicatorはワーカプロセス間の通信を担います。ワーカプロセスには0番からn(並列数)番までのRankと呼ばれる番号が割り当てられます。<br>\n",
    "GPUを用いて実行する場合は、create_communicatorを用いて以下のようにCommunicatorを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comm = chainermn.create_communicator('hierarchical')\n",
    "device = comm.intra_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、GPUの使用の宣言をし、modelをGPUへ送る必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chainer.cuda.get_device(device).use()\n",
    "model.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPUのみを用いて実行する場合は以下のようにCommunicatorを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comm = chainermn.create_communicator('naive')\n",
    "device = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Multi-Node Optimizerを作成します。<br>\n",
    "create_multi_node_optimizerにChainerのOptimizerとCommunicatorを与えることで、分散対応したOptimizerを作成します。<br>\n",
    "ChainerMNのOptimizerはChainerのOptimizerと同様に扱うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = chainermn.create_multi_node_optimizer(chainer.optimizers.Adam(), comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークのモデルをOptimizerに設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、学習データの準備をします。<br>\n",
    "ここでは、MNISTのデータを取得し、各ワーカプロセスに配布します。<br>\n",
    "まず、MNISTの訓練データ、テストデータを取得します。<br>\n",
    "ワーカプロセスが0番のときはMNISTのデータを取得し、その他の場合は何もしません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if comm.rank == 0:\n",
    "    train, test = chainer.datasets.get_mnist()\n",
    "else:\n",
    "    train, test = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後、0番のワーカプロセスが取得したMNISTのデータを他のワーカプロセスに配布します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = chainermn.scatter_dataset(train, comm)\n",
    "test = chainermn.scatter_dataset(test, comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、各ワーカプロセスで訓練データとテストデータのIteratorを作成します。今、ミニバッチサイズを100とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習処理を実際に行うTrainerの設定を行います。ここでは、20 epochを実行し、resultに出力します。<br>\n",
    "Updaterに各種最適化手法を設定することができます。詳細は以下のサイトを参照してください。<br>\n",
    "http://docs.chainer.org/en/latest/tutorial/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データを基に学習したモデルを分散して評価するために、MultinodeEvaluationrを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = extensions.Evaluator(test_iter, model, device=device)\n",
    "evaluator = chainermn.create_multi_node_evaluator(evaluator, comm)\n",
    "trainer.extend(evaluator)\n",
    "if comm.rank == 0:\n",
    "    trainer.extend(extensions.dump_graph('main/loss'))\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.PrintReport(\n",
    "        ['epoch', 'main/loss', 'validation/main/loss', \n",
    "         'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
    "    trainer.extend(extensions.ProgressBar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで準備が揃ったので、実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
